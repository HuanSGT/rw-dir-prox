\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{bm}
\usepackage{dsfont}

\newtheorem*{mythm*}{Theorem}
\newtheorem*{mylem*}{Lemma}
\newtheorem*{mycor*}{Corollary}

\begin{document}

\begin{itemize}
\item The generalized voltage $v_k$
\begin{itemize}
\item $v_k \triangleq $ Pr[A random walk starting at $k$ visits $j$ before $i$]
\end{itemize}
\item Calculating $\bm{v} \triangleq (v_1\ v_2\ \cdots\ v_n)^\top$
\begin{itemize}
\item $v_i = 0$ and $v_j = 1$
\item $\forall k\neq i, j$, $v_k = \sum\limits_l p_{kl} \cdot v_l$
\item Split
$\bm{P} = \begin{pmatrix}
\hat{\bm{P}} & \bm{c}_i & \bm{c}_j \\
\bm{r}_i^\top & 0 & p(i,j) \\
\bm{r}_j^\top & p(j,i) & 0
\end{pmatrix}$
and $\bm{v} = \begin{pmatrix} \hat{\bm{v}} & 0 & 1 \end{pmatrix}^\top$
\item Then $\hat{\bm{v}} = \hat{\bm{P}} \hat{\bm{v}} + \bm{r}_j \ \Rightarrow\ \hat{\bm{v}} = (\bm{I} - \hat{\bm{P}})^{-1} \bm{r}_j$
\end{itemize}
\item $\mathrm{ep}(i\rightarrow j) = \sum\limits_k p_{ik} \cdot v_k = \bm{r}_i^\top (\bm{I} - \hat{\bm{P}})^{-1} \bm{c}_j + p(i,j)$
\item Computing all $\mathrm{ep}(i\rightarrow j)$ requires $\Theta(n^2)$ matrix inversions
\end{itemize}

\begin{mythm*}
Let
\[
\bm{Q} = \left[ q(i,j) \right] \triangleq (\bm{I} - c\bm{P})^{-1}.
\]
$\forall i\neq j$, there is
\[
\mathrm{ep}(i\rightarrow j) = \frac{q(i,j)}{q(i,i)q(j,j) - q(i,j)q(j,i)}.
\]
\end{mythm*}

\begin{itemize}
\item Fast solution to all-pair proximities
\begin{itemize}
\item Compute $\bm{Q} = (\bm{I} - c\bm{P})^{-1}$
\item For all pair of nodes i and j, compute $\mathrm{Prox}(i,j) = \frac{q(i,j)}{q(i,i)q(j,j) - q(i,j)q(j,i)}$
\end{itemize}
\item Time complexity $\Theta(\mathrm{1\ matrix\ inversion}) + \Theta(n^2)$
\end{itemize}

\begin{itemize}
\item When only the proximity of one pair of nodes
\begin{itemize}
\item Only need two columns of $\bm{Q}$
\item Taylor expansion
\[(\bm{I} - c\bm{P})^{-1} = \bm{I} + c\bm{P} + (c\bm{P})^2 + \cdots\]
\item Computing $i$-th column of $\bm{Q}$
\begin{align*}
\bm{Q}\bm{e}_i &= (\bm{I} - c\bm{P})^{-1} \bm{e}_i = \bm{e}_i + c\bm{P} \bm{e}_i + (c\bm{P})^2 \bm{e}_i + \cdots
\end{align*}
\end{itemize}
\item Time complexity $\Theta\left(t(n + m)\right)$, where $t$ is the number of iterations
\end{itemize}

\begin{mylem*}
The expected time $r_i$ for a random walk starting at node $i$ to return to $i$ is the reciprocal of the stationary probability of $i$.
That is
\[
r_i = \frac{1}{\pi_i}.
\]
\end{mylem*}

\begin{itemize}
\item Intuitively
\begin{itemize}
\item A long walk always ends up in stationary distribution $\bm{\pi}$
\item Suppose the walk length is $T$, then the expected number of times it visits $i$ is $\pi_i \cdot T$
\item The average length between two visits is $\frac{T}{\pi_i \cdot T} = \frac{1}{\pi_i}$
\item A rigorous proof requires the Strong Law of Large Numbers
\end{itemize}
\end{itemize}

\begin{mythm*}
The probability that a random walk starting at node $i$ visits $j$ before returning to $i$, which equals $\mathrm{ep}(i\rightarrow j)$, satisfies
\[
\mathrm{ep}(i\rightarrow j)c(i,j) = \frac{1}{\pi_i},
\]
where $c(i,j)$ is the commute time between $i$ and $j$.
\end{mythm*}

\begin{itemize}
\item Proof
\begin{itemize}
\item Consider a random walk $w$ starting at $i$, and random variables
\begin{itemize}
\item $X = $ the first time $w$ returns to $i$
\item $Y = $ the first time $w$ returns to $i$ after visiting $j$
\end{itemize}
\item By definition $E(X) = \frac{1}{\pi_i}$ and $E(Y) = c(i,j)$
\item Clearly $X \leq Y$, and $\Pr\left[X = Y\right] = p \triangleq \mathrm{ep}(i\rightarrow j)$
\begin{itemize}
\item $E(Y - X) = p\cdot 0 + (1 - p)\cdot E(Y) = (1-p) c(i,j)$
\end{itemize}
\item Also $E(Y - X) = E(Y) - E(X) = c(i,j) - \frac{1}{\pi_i}$
\end{itemize}
\end{itemize}

\begin{itemize}
\item $\mathrm{ep}(i\rightarrow j) + \mathrm{ep}(j\rightarrow i) = \frac{1}{c(i,j)}\left(\frac{1}{\pi_i} + \frac{1}{\pi_j}\right)$
\item Recall that $h(i,j)$ is small whenever $\pi_j$ is large, which is bad for personalization
\begin{itemize}
\item Sarkar et al. (2008) alleviate this by restricting the length of random walk
\item Tong et al. (2007) alleviate this by reducing the dependence on stationary distribution
\end{itemize}
\end{itemize}

\end{document}
